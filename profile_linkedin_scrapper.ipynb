{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkedin Profile Scrapper\n",
    "*This is **NOT** a real project, it's only used to learning the scrapping concept.*\n",
    "\n",
    "### Problem Statement:\n",
    "A school need to know how many and who are the LinkedIn Alumnis.\n",
    "\n",
    "### Solution:\n",
    "A web scrapping to find all users in Alumnis section on LinkedIn's School and save it ins a CSV file.\n",
    "\n",
    "### Libs\n",
    "- OS - To manipulate local variables\n",
    "- Time - To wait page loads\n",
    "- Pandas - To load and manipulate data\n",
    "- Selenium - To emulate and navegate in a browser\n",
    "- Scrapy - To scrap data from a website\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Importing libs and load local variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from scrapy import Selector\n",
    "import random\n",
    "\n",
    "login_username = os.getenv('LINKEDIN_USER')\n",
    "password = os.getenv('LINKEDIN_PASSWORD')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Access url of School's LinkedIn\n",
    "2.1 Use local variables do login\\\n",
    "2.2 Access the url\\\n",
    "2.3 Scroll a couple of times (important, the number of scroll depends on number of alumnis)\n",
    "\n",
    "\n",
    "*to do: Get the number of Alumnis to determine the number of scrolls.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe Mayer\\AppData\\Local\\Temp\\ipykernel_8220\\983448309.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"Users\\Felipe Mayer\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"Users\\Felipe Mayer\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    "  \n",
    "# waiting for the page to load\n",
    "time.sleep(5)\n",
    "  \n",
    "# entering username\n",
    "username = driver.find_element(By.XPATH, \"//input[@id='username']\")\n",
    "\n",
    "# Enter Your Email Address\n",
    "username.send_keys(login_username)  \n",
    "  \n",
    "# entering password\n",
    "pword = driver.find_element(By.XPATH, \"//input[@id='password']\")\n",
    "  \n",
    "# Enter Your Password\n",
    "pword.send_keys(password)        \n",
    "\n",
    "# Press login button\n",
    "driver.find_element(By.XPATH, \"//button[@class='btn__primary--large from__button--floating']\").submit()\n",
    "\n",
    "# School Linkedin URL\n",
    "url = \"https://www.linkedin.com/school/cursos-pm3/people/\"\n",
    "  \n",
    "driver.get(url)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "for x in range(1, 200):\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, './/span[text()=\"Show more results\"]/parent::button').click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "src = driver.page_source\n",
    "\n",
    "sel = Selector(text=src)\n",
    "\n",
    "time.sleep(5)\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Get the Alumnis profile urls\n",
    "3.1 Transform the page source provided by Driver into a Scrapy Selector.\\\n",
    "3.2 Using xpath, get all alumnis url's containers.\\\n",
    "3.3 Iterate over urls and add them to dataframe.\\\n",
    "3.4 Drop URL duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linkedin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/in/gicosilvaalmeida?m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/in/falacomcaio?miniPr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/in/guipaulobarros?min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/in/felipeperazza?mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/in/gabrieltarantelli?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>https://www.linkedin.com/in/joaotorreslima?min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>https://www.linkedin.com/in/filipe-oliveira-66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>https://www.linkedin.com/in/gabitonunes?miniPr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.linkedin.com/in/emerson-birochi-14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>https://www.linkedin.com/in/thaisgaldini?miniP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              linkedin\n",
       "0    https://www.linkedin.com/in/gicosilvaalmeida?m...\n",
       "1    https://www.linkedin.com/in/falacomcaio?miniPr...\n",
       "2    https://www.linkedin.com/in/guipaulobarros?min...\n",
       "3    https://www.linkedin.com/in/felipeperazza?mini...\n",
       "4    https://www.linkedin.com/in/gabrieltarantelli?...\n",
       "..                                                 ...\n",
       "993  https://www.linkedin.com/in/joaotorreslima?min...\n",
       "994  https://www.linkedin.com/in/filipe-oliveira-66...\n",
       "995  https://www.linkedin.com/in/gabitonunes?miniPr...\n",
       "996  https://www.linkedin.com/in/emerson-birochi-14...\n",
       "997  https://www.linkedin.com/in/thaisgaldini?miniP...\n",
       "\n",
       "[997 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = sel.xpath('.//section/div/div/div/a[contains(@href, \"/in/\")]/@href')\n",
    "\n",
    "df_alumnis = pd.DataFrame()\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    df_alumnis.loc[i, 'linkedin'] = url.get()\n",
    "\n",
    "df_alumnis = df_alumnis.drop_duplicates(keep=\"last\").copy()\n",
    "\n",
    "df_alumnis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Extract the content (as Selector) of each line of dataframe\n",
    "4.1 Iterate over the dataframe\\\n",
    "4.2 For each iteration, needed to create a new driver (to bypass scrap-blockers)\\\n",
    "4.3 Dismiss the modal if it was created\\\n",
    "4.4 Add a new column in dataframe with the content (selector) of each profile\\\n",
    "4.5 Close Driver to new iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_alumnis.sample(frac=1/5).iterrows():\n",
    "        # Creating a webdriver instance\n",
    "        driver = webdriver.Chrome(r\"Users\\Felipe Mayer\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "        # open browser with current user linkedin url as parameter\n",
    "        driver.get(row['linkedin'])\n",
    "        time.sleep(random.randint(2, 5))\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"contextual-sign-in\"]/div/section/button').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        src = driver.page_source\n",
    "\n",
    "        df_alumnis.loc[i, 'selector'] = Selector(text=src)\n",
    "\n",
    "        driver.close()\n",
    "        time.sleep(random.randint(2, 5))\n",
    "\n",
    "df_alumnis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Extract and organize the content (Selector)\n",
    "\n",
    "5.1 Drop the na rows, just to avoid errors\\\n",
    "5.2 Itearate over a dataframe\\\n",
    "5.3 Using the xpath get the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alumnis = df_alumnis.loc[~df_alumnis['selector'].isna()].reset_index().copy()\n",
    "\n",
    "for i, row in df_alumnis.iterrows():\n",
    "\n",
    "    df_alumnis.loc[i, 'status'] = 'Public'\n",
    "    df_alumnis.loc[i, 'name'] = row['selector'].xpath('//h1/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'headline'] = row['selector'].xpath('//h2/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'local'] = row['selector'].xpath('//h3/div/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'about'] = row['selector'].xpath('//h2[contains(text(),\"About\")]/following-sibling::div/p/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'job_title'] = row['selector'].xpath('//section[contains(@class,\"experience\")]/div/ul/li[1]/div/h3/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'current_company'] = row['selector'].xpath('//section[contains(@class,\"experience\")]/div/ul/li[1]/div/h4/a/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'job_duration'] =  row['selector'].xpath('//section[contains(@class,\"experience\")]/div/ul/li[1]/div/div/p/span/span/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'job_description'] = row['selector'].xpath('//section[contains(@class,\"experience\")]/div/ul/li[1]/div/div/div/div/p/text()').get(default='').replace('\\n', ' ').strip()\n",
    "    df_alumnis.loc[i, 'job_local'] = row['selector'].xpath('//section[contains(@class,\"experience\")]/div/ul/li[1]/div/div/p[2]/text()').get(default='').replace('\\n', ' ').strip()\n",
    "\n",
    "display(df_alumnis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 6 - Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alumnis.to_csv(\"alumnis.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58df9fa0e90299bf3bde098e8a523f66fe469562edc0f7aa230408e563ae91f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
